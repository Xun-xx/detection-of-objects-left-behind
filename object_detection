#include<opencv2/core/core.hpp>

#include<opencv2/imgproc/imgproc.hpp>
#include<iostream>
#include<ctime>
#include<queue>
#include "hisi/hi_ive.h"
#include "hisi/hi_comm_ive.h"
#include "hisi/mpi_ive.h"
#include "opencv2/opencv.hpp"
#include <sys/time.h>
#include "version.h"
//#include "dtracker.h"
//#include "deepcam_nnie.h"
//#include "highgui.h"



#include <dirent.h>

#include "hisi/hi_comm_vpss.h"
#include "hisi/mpi_vpss.h"
#include "hisi/hi_comm_svp.h"
#include "sample_comm.h"
#include "sample_comm_svp.h"
#include "deepcam_tracker.h"
#include "dev_info_service.h"

#include "AuthUtil.hpp"
#include "fd_process.h"


using namespace cv;
using namespace std;
typedef struct tagIPC_IMAGE{
	HI_U64      u64PhyAddr;
	HI_U64      u64VirAddr;
	HI_U32      u32Width;
	HI_U32      u32Height;
}IPC_IMAGE;

HI_S32 yuvFrame2rgb(VIDEO_FRAME_INFO_S *srcFrame,IPC_IMAGE *dstImage)
{
    IVE_HANDLE hIveHandle;
    IVE_SRC_IMAGE_S pstSrc;
    IVE_DST_IMAGE_S pstDst;
    IVE_CSC_CTRL_S stCscCtrl;
    HI_S32 s32Ret = 0;
    stCscCtrl.enMode = IVE_CSC_MODE_PIC_BT709_YUV2RGB;//IVE_CSC_MODE_VIDEO_BT601_YUV2RGB;
    pstSrc.enType = IVE_IMAGE_TYPE_YUV420SP;
    pstSrc.au64VirAddr[0]=srcFrame->stVFrame.u64VirAddr[0];
    pstSrc.au64VirAddr[1]=srcFrame->stVFrame.u64VirAddr[1];
    pstSrc.au64VirAddr[2]=srcFrame->stVFrame.u64VirAddr[2];

    pstSrc.au64PhyAddr[0]=srcFrame->stVFrame.u64PhyAddr[0];
    pstSrc.au64PhyAddr[1]=srcFrame->stVFrame.u64PhyAddr[1];
    pstSrc.au64PhyAddr[2]=srcFrame->stVFrame.u64PhyAddr[2];

    pstSrc.au32Stride[0]=srcFrame->stVFrame.u32Stride[0];
    pstSrc.au32Stride[1]=srcFrame->stVFrame.u32Stride[1];
    pstSrc.au32Stride[2]=srcFrame->stVFrame.u32Stride[2];

    pstSrc.u32Width = srcFrame->stVFrame.u32Width;
    pstSrc.u32Height = srcFrame->stVFrame.u32Height;

    pstDst.enType = IVE_IMAGE_TYPE_U8C3_PACKAGE;
    pstDst.u32Width   = pstSrc.u32Width;
    pstDst.u32Height  = pstSrc.u32Height;
    pstDst.au32Stride[0]  = pstSrc.au32Stride[0];
    pstDst.au32Stride[1]  = 0;
    pstDst.au32Stride[2]  = 0;
    s32Ret = HI_MPI_SYS_MmzAlloc_Cached(&pstDst.au64PhyAddr[0], (void **)&pstDst.au64VirAddr[0], "User", HI_NULL, pstDst.u32Height*pstDst.au32Stride[0]*3);
    if(HI_SUCCESS != s32Ret)
    {       
        HI_MPI_SYS_MmzFree(pstDst.au64PhyAddr[0], (void *)pstDst.au64VirAddr[0]);
       // LOG(ERROR)<<"HI_MPI_SYS_MmzAlloc_Cached Failed with 0x"<<hex<<s32Ret<<endl;
        return s32Ret;
    }
    memset((void *)pstDst.au64VirAddr[0], 0, pstDst.u32Height*pstDst.au32Stride[0]);
    s32Ret = HI_MPI_SYS_MmzFlushCache(pstDst.au64PhyAddr[0], (void *)pstDst.au64VirAddr[0], pstDst.u32Height*pstDst.au32Stride[0]);
    if(HI_SUCCESS != s32Ret)
    {       
        HI_MPI_SYS_MmzFree(pstDst.au64PhyAddr[0], (void *)pstDst.au64VirAddr[0]);
       // LOG(ERROR)<<"HI_MPI_SYS_MmzFlushCache Failed with 0x"<<hex<<s32Ret<<endl;
        return s32Ret;
    }
    HI_BOOL bInstant = HI_TRUE;
    s32Ret = HI_MPI_IVE_CSC(&hIveHandle,&pstSrc,&pstDst,&stCscCtrl,bInstant);
    if(HI_SUCCESS != s32Ret)
    {       
        HI_MPI_SYS_MmzFree(pstDst.au64PhyAddr[0], (void *)pstDst.au64VirAddr[0]);
        //LOG(ERROR)<<"HI_MPI_IVE_CSC Failed with 0x"<<hex<<s32Ret<<endl;
        return s32Ret;
    }
    if (HI_TRUE == bInstant)
    {
        HI_BOOL bFinish = HI_TRUE;
        HI_BOOL bBlock = HI_TRUE;
        s32Ret = HI_MPI_IVE_Query(hIveHandle,&bFinish,bBlock);
        while(HI_ERR_IVE_QUERY_TIMEOUT == s32Ret)
        {
            usleep(100);
            s32Ret = HI_MPI_IVE_Query(hIveHandle,&bFinish,bBlock);
        }
    }
    dstImage->u64PhyAddr = pstDst.au64PhyAddr[0];
    dstImage->u64VirAddr = pstDst.au64VirAddr[0];
    dstImage->u32Width = pstDst.u32Width;
    dstImage->u32Height = pstDst.u32Height;
    return HI_SUCCESS;
}
HI_S32 frame2Mat(VIDEO_FRAME_INFO_S *srcFrame,Mat &dstMat)
{
    HI_U32 w = srcFrame->stVFrame.u32Width;
    HI_U32 h = srcFrame->stVFrame.u32Height;
    int bufLen = w*h*3;
    HI_U8 *srcRGB = NULL;
    IPC_IMAGE dstImage;
    if(yuvFrame2rgb(srcFrame,&dstImage)!=HI_SUCCESS){
        //LOG(ERROR)<<"yuvFrame2rgb Err ."<<endl;
        return HI_FAILURE;
    }
    srcRGB = (HI_U8 *)dstImage.u64VirAddr;
    dstMat.create(h, w, CV_8UC3);
    memcpy(dstMat.data, srcRGB, bufLen*sizeof(HI_U8));
    HI_MPI_SYS_MmzFree(dstImage.u64PhyAddr, (void *)&(dstImage.u64VirAddr));
    return HI_SUCCESS;
}

unsigned long get_cur_time(void)
{
 struct timeval tv;
 unsigned long ts;

 gettimeofday(&tv,NULL);

 ts=tv.tv_sec*1000000+tv.tv_usec;
 return ts;
}

float getmin(float a, float b){
    return a < b ? a : b;
}
float getmax(float a, float b){
    return a > b ? a : b;
}

// 返回2表示遗留，1表示移除
int detectLeftRemove(Mat background, Rect rect)
{	
	int returnVal = -1;
	Rect surroundRect;
	surroundRect.x = std::max(0,rect.x-15); // 外移10个像素
	surroundRect.y = std::max(0,rect.y-15);
 
	if ( (surroundRect.y+rect.height+30) > background.rows )	
		surroundRect.height = background.rows- surroundRect.y;	
	else
		surroundRect.height = rect.height+30;
 
	if ( (surroundRect.x+rect.width+30) > background.cols )	
		surroundRect.width = background.cols- surroundRect.x;	
	else
		surroundRect.width = rect.width+30;	
	Scalar S1 = mean(background(rect));
	Scalar S2 = mean(background(surroundRect));
	double dist1 = norm(S1);
	double dist2 = norm(S2);
	double ratio = 0.0;
	if ( dist1>= dist2 )
		ratio = dist2/dist1;
	else
		ratio = dist1/dist2;
 
	if (ratio>=0.85 && ratio<=1.0)	// 相近表示离开（ Remove ）	
		returnVal = 1;		
	else	  // 否则表示遗留（Left）	
		returnVal = 2;	
	
	return returnVal;	
}

//void myGMM(Mat src,Mat bgsub,int npixel);
int main(int argc, char *argv[])
{
	
	#if 1
	VIDEO_FRAME_S* stVFrame;			//人脸识别视频源参数
	void *handle;
	void *gfacehandle;
	VPSS_GRP VpssGrp = 0;
	VPSS_CHN VpssChn = 0;
	char *ModelPath = NULL;
	unsigned long start,end,objstart,objend,objtotal;
	HI_S32 s32Ret;
	HI_S32 s32MilliSec = 100;
	HI_S32 head_count = 0;
	HI_S32 minsize = 40;
	struct FaceInfo headBoxs;
	VIDEO_FRAME_INFO_S stFrame;
	HI_U64 u64PTS;
	RW_Face_Info stFRInfo[64];

	char uuid[] = "12621SSSSJP4";
	char key[] = "B8BA5AE4AC2DAA6A54CFF50321F3C688";
	set_key_uuid(key, uuid);
	struct FuncEnable funcEnable;

	funcEnable.face_detect = false;
	funcEnable.face_match = false;
	funcEnable.age = false;
	funcEnable.gender = false;		
	


	FDFaceSyncShmInit();
	VpssGrp = atoi(argv[1]); /* grp id */
	if (!VALUE_BETWEEN(VpssGrp, 0, VPSS_MAX_GRP_NUM - 1))
	{
		printf("grp id must be [0,%d]!!!!\n\n", VPSS_MAX_GRP_NUM - 1);
		return -1;
	}
	VpssChn = atoi(argv[2]); /* chn id */
	if (!VALUE_BETWEEN(VpssChn, 0, VPSS_MAX_CHN_NUM - 1))
	{
		printf("chn id must be [0,%d]!!!!\n\n", VPSS_MAX_CHN_NUM - 1);
		return -1;
	}
	ModelPath = argv[3]; /* model path */
	if (0 == strlen(ModelPath))
	{
		printf("model path is empty!!!!\n\n");
		return -1;
	}
	gfacehandle = tracker_initialize(ModelPath, &funcEnable);
	struct objectInfo motorBoxes;
	struct objectInfo bicycleBoxes;
	struct objectInfo personBoxes;
	HI_S32 car_count = 0, bicycle_count = 0, person_count = 0;

	motorBoxes.objectCount = 0;
	bicycleBoxes.objectCount = 0;
	personBoxes.objectCount = 0;
	
	
	//char* imageSaveName = new char[200];

    clock_t startTime,endTime,objTime,objendTime,objtotalTime;
	double totalTime;
	
 	string filename;	
	vector<vector<Point> > contours;
	vector<Vec4i> hierarchy;
	
	
	double sum1area; // 并集面积
	double sum2area; // 交集面积
	
	
	
	Mat img,diff,back,aban(200,200,CV_8UC1,Scalar(0)),sub,testimg,element,tmp;
	
		
	int countsizetest =0;
			
	int i=0,j=0;
	
	int count=0;//to count number of frames
	int npixel=100;//change this value to increase number of averaged pixels

	int col2[160][160];
	int sum2[160][160]={0};
	float avgq2[160][160]={0};

	int type = 0;

	int persontestx ;
	int persontesty ;
	int persontestw ;
	int persontesth ;
	
	queue<int>colq2[160][160];
	int flag=0;
	int testcount = 0;
	int leavecount = 0;
	int leave = 0;
	//startTime = clock();
	clock_t clk=clock()/CLOCKS_PER_SEC;//hold time in seconds b/w excecution and this statement
	while(true)
	{
		
		s32Ret = HI_MPI_VPSS_GetChnFrame(VpssGrp, VpssChn, &stFrame, s32MilliSec);
		
		frame2Mat(&stFrame,img);
			
		startTime = clock();
		int ret = tracker_detect(gfacehandle, &stFrame.stVFrame, minsize, &motorBoxes, &bicycleBoxes, &personBoxes);
		if(ret < 0)
		{
		printf("tracker detect failed!\n");
		HI_MPI_VPSS_ReleaseChnFrame(VpssGrp, VpssChn, &stFrame);
		//HI_MPI_VPSS_ReleaseChnFrame(DEEPCAM_GPR, DEEPCAM_SNAP_CHN, &stFrameMain);
	
		//continue;
		}
		if (ret > 0)
		{
		printf("\n\n***************************motor[%d] bicycle[%d] person[%d]\n",
			motorBoxes.objectCount, bicycleBoxes.objectCount, personBoxes.objectCount);
		/* if(personBoxes.objectCount>0)
		{
			leavecount++;
		} */
		if(personBoxes.objectCount > 0)
				{
						type = 1;
					
				}
				
		for (int i=0; i<motorBoxes.objectCount; i++)
		{
			printf("motor[%d], class_id[%d] tracker_id[%d] x[%d] y[%d] w[%d] h[%d]\n",
				i, motorBoxes.classID[i], motorBoxes.trackerID[i], 
				motorBoxes.x[i], motorBoxes.y[i], 
				motorBoxes.w[i], motorBoxes.h[i]);
		}

		for (int i=0; i<bicycleBoxes.objectCount; i++)
		{
			printf("bicycle[%d], class_id[%d] tracker_id[%d] x[%d] y[%d] w[%d] h[%d]\n",
				i, bicycleBoxes.classID[i], bicycleBoxes.trackerID[i], 
				bicycleBoxes.x[i], bicycleBoxes.y[i], 
				bicycleBoxes.w[i], bicycleBoxes.h[i]);
		}

		for (int i=0; i<personBoxes.objectCount; i++)
		{
			printf("person[%d], class_id[%d] tracker_id[%d] x[%d] y[%d] w[%d] h[%d]\n",
				i, personBoxes.classID[i], personBoxes.trackerID[i], 
				personBoxes.x[i], personBoxes.y[i], 
				personBoxes.w[i], personBoxes.h[i]);
				
				
		}				
		}
		
		Rect r(0,65,img.cols,img.rows-65);
		testimg = img ;
   		testimg = testimg(r); 
		
	
		resize(testimg,testimg,Size(160,160));
	    img=img(r);
		resize(img,img,Size(160,160));
		
		count++;
		cvtColor(img,img,CV_BGR2GRAY);
						
		diff=img.clone();
		absdiff(img,img,diff);
		 	
		back=img.clone();
		
		absdiff(back,back,back);

		
		//Implementation on whole image___________________________________________________________
		 for(i=0;i<160;i++)
			{
				for(j=0;j<160;j++)
					{
						col2[i][j]=img.at<uchar>(Point(i,j));//save latest value
						colq2[i][j].push(col2[i][j]);//push latest value
						if(count<npixel)
							{
								sum2[i][j]=sum2[i][j]+col2[i][j];
								avgq2[i][j]=0;	//avg zero till queue is full
							}
						if(count>=npixel)//Background acquisition complete
							{ 
								colq2[i][j].pop();//take latest pixel
								sum2[i][j]=sum2[i][j]+col2[i][j]-colq2[i][j].front();//take sum of latest 150 pixels
								avgq2[i][j]=sum2[i][j]/npixel;
						
							
							}
						back.at<uchar>(Point(i,j))=avgq2[i][j];//get averaged background
							if(col2[i][j]-avgq2[i][j]>10 || col2[i][j]-avgq2[i][j]<(-10))
							{
								diff.at<uchar>(Point(i,j))=col2[i][j];// BG modelling step
	
							}
			        
					}
			} 

				
			  if(count<npixel)
			{
				
				putText(back,".",Point(10,30),FONT_HERSHEY_SIMPLEX,0.5,Scalar(255),1);
				
				
			}
			//Background Subtraction ends here__________________________________________________
		
			int interval;
			//createTrackbar("Interval","Abandoned Objects",&interval,600);//max interval of 10 minutes
			if(flag==0)//initial block in verilog, with delay
			{
				 absdiff(back,back,aban);//initialize aban once only
				 interval=300; //to initialize trackbar position once at 60 seconds
				 flag=10 ;
			 }
	
			if(flag==10 && count>=npixel )//this loop runs once
			 {
				 aban=back.clone();//extra loop run to ensure stable initial background
				 flag =20;
			 }
			//cout<<"interval = "<<clock()/CLOCKS_PER_SEC-clk<<"\n";
			if(clock()/CLOCKS_PER_SEC-clk>=interval )//interval can vary from 0 to 10 minutes; infinite loop
			{
			cout<<"New Interval \n";
			aban=back.clone();//not aban=back as they'll become pointers pointing to same address
			clk=clock()/CLOCKS_PER_SEC;
			}  
			
			
			
			
			absdiff(back,aban,sub);
			tmp = sub;
			//resize(sub,sub,Size(1920,1080));
			GaussianBlur(sub, sub, Size(3, 3), 1);
			threshold(sub, sub, 30, 255.0, CV_THRESH_BINARY);
			element = getStructuringElement(MORPH_RECT, Size(3, 3));//3*3全1结构元素
			
			dilate( sub, sub, element );
			erode( sub, sub, element );
			
			cv::morphologyEx(sub, sub, cv::MORPH_CLOSE, element);
			resize(sub,sub,Size(1920,1080));
			
			findContours(sub , contours, hierarchy, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_NONE);//CV_RETR_EXTERNAL只检测外部轮廓，可根据自身需求进行调整
			//findContours(sub , contours, hierarchy, CV_RETR_TREE, CV_CHAIN_APPROX_NONE);
			
			if(contours.size() >=1)
			{
				testcount++;
			}
		
			if(testcount > 200)
					
			{
				objstart = get_cur_time();
				printf("objstart %dms\n", objstart/1000);
				
			}
			
			Mat contoursImage(sub.rows, sub.cols, CV_8U, Scalar(255));
			
			int index = 0;
			for (; index >= 0; index = hierarchy[index][0])
			{
			cv::Scalar color(rand() & 255, rand() & 255, rand() & 255);
			// for opencv 2
			// cv::drawContours(dstImage, contours, index, color,  CV_FILLED, 8, hierarchy);//CV_FILLED所在位置表示轮廓线条粗细度，如果为负值（如thickness==cv_filled），绘制在轮廓内部
			// for opencv 3
			//cv::drawContours(contoursImage, contours, index, color, cv::FILLED, 8, hierarchy);
			
			cv::drawContours(contoursImage, contours, index, Scalar(0), 1, 8, hierarchy);//描绘字符的外轮廓
			
			
				
							
			
			
				vector<Rect> boundRect(contours.size());
				vector<vector<Point> > contours_poly(contours.size());
			
			memset(&stFRInfo, 0, sizeof(stFRInfo));
			cout<<"contours.size:"<<contours.size()<<endl;
			 for (int i = 0; i < contours.size(); i++)
			{ 
				
				
				
				approxPolyDP(contours[i], contours_poly[i], 3, true);
			
				boundRect[i] = boundingRect(Mat(contours[i]));
				//Rect rect = boundingRect(contours[index]);//检测外轮廓
				Rect rect = boundingRect(contours[i]);
				
				
				cout<<"123"<<endl;
				int detectleft = detectLeftRemove(tmp,rect);
				cout<<"234"<<endl;
				if(detectleft = 2)
				{
					stFRInfo[i].x = boundRect[i].tl().x;
					stFRInfo[i].y = boundRect[i].tl().y;
					stFRInfo[i].w = boundRect[i].width;
					stFRInfo[i].h = boundRect[i].height; 
					u64PTS = stFrame.stVFrame.u64PTS;
					FDProcessSaveResult(&stFRInfo[0], contours.size(), u64PTS);
				}
				
				
				/* if(personBoxes.objectCount > 0)
				{
					
					for (int j=0; j<personBoxes.objectCount; j++)
					{      
							if(rect.x >  personBoxes.x[j] && rect.x < (personBoxes.x[j]+personBoxes.w[j]) &&
								rect.y > personBoxes.y[j] && rect.y < (personBoxes.y[j]+personBoxes.w[j]))
								{
									boundRect[i] = {(0,0),(0,0),0,0};
								}
								
					float wide1 = getmin((personBoxes.x[j] + personBoxes.w[j]), (rect.x + rect.width) - getmax(personBoxes.x[j], rect.x));
					float height1 = getmin((personBoxes.y[j] + personBoxes.h[j]), (rect.y + rect.height) - getmax(personBoxes.y[j], rect.y));
					sum1area = wide1*height1;
					float wide2 = getmax((personBoxes.x[j] + personBoxes.w[j]), (rect.x + rect.width) - getmin(personBoxes.x[j], rect.x));
					float height2 = getmax((personBoxes.y[j] + personBoxes.h[j]), (rect.y + rect.height) - getmin(personBoxes.y[j], rect.y));
					sum2area = wide2*height2;
					cout<<"sum1area/sum2area"<<sum1area/sum2area<<endl;
					if(sum1area/sum2area > 0.5)
					{
						
						boundRect[i] = {(0,0),(0,0),0,0};
					}
					
						}
				} */
					
					/* if((personBoxes.w[j]*personBoxes.h[j])/ (rect.width*rect.height) > 0.6 && 
					(personBoxes.w[j]*personBoxes.h[j])/ (rect.width*rect.height) < 1.4)
					{
						cout<<"(persontestw*persontesth)/ (rect.width*rect.height)"<<(persontestw*persontesth)/ (rect.width*rect.height)<<endl;
						
						boundRect[i] = {(0,0),(0,0),0,0};
					} */
					/* for (int j=0; j<personBoxes.objectCount; j++)
					{
						
						
					if(personBoxes.w[j]*personBoxes.h[j] / boundRect[i].width*boundRect[i].height > 0.85 ||
					personBoxes.w[j]*personBoxes.h[j] / boundRect[i].width*boundRect[i].height < 1.15)
					{
						boundRect[i] = {(0,0),(0,0),0,0};
					}
					
					
					
					} */
					
					
								
				
				
				
			
			//rectangle(contoursImage, rect, Scalar(0,0,255), 2);//对外轮廓加矩形框
			
			
			/* cout<<"boundRect"<<i<<".tl().x:"<<boundRect[i].tl().x<<endl;
			cout<<"boundRect"<<i<<".tl().y:"<<boundRect[i].tl().y<<endl;
			cout<<"boundRect"<<i<<".width:"<<boundRect[i].width<<endl;
			cout<<"boundRect"<<i<<".height:"<<boundRect[i].height<<endl;
			
			
			cout<<"rect.x"<<rect.x<<endl;
			cout<<"rect.y"<<rect.y<<endl;
			cout<<"rect.width"<<rect.width<<endl;
			cout<<"rect.height"<<rect.height<<endl; */
			
		/* 	stFRInfo[i].x = boundRect[i].tl().x*(1920/160);
			stFRInfo[i].y = boundRect[i].tl().y*(1080/160+0.75);//(1920/160);
			stFRInfo[i].w = boundRect[i].width*(1920/160);
			stFRInfo[i].h = boundRect[i].height*(1080/160+0.75);  */
			 
			
			 
			 
			 
		   /*  stFRInfo[i].x = boundRect[i].tl().x;
			stFRInfo[i].y = boundRect[i].tl().y;
			stFRInfo[i].w = boundRect[i].width;
			stFRInfo[i].h = boundRect[i].height;  */
			
			/* stFRInfo[i].x = (unsigned short)boundRect[i].tl().x*4;
			stFRInfo[i].y = (unsigned short)boundRect[i].tl().y*4;
			stFRInfo[i].w = (unsigned short)boundRect[i].width*4;
			stFRInfo[i].h = (unsigned short)boundRect[i].height*4;  */
		
				/* stFRInfo[i].x = (unsigned short)rect.x*(1920/160);
				stFRInfo[i].y = (unsigned short)rect.y*(1080/160+0.75);
				stFRInfo[i].w = (unsigned short)rect.width*(1920/160);
				stFRInfo[i].h = (unsigned short)rect.height*(1080/160+0.75);  */
				/* cout<<"stFRInfo[i].x:"<<stFRInfo[i].x<<endl;
				cout<<"stFRInfo[i].y:"<<stFRInfo[i].y<<endl;
				cout<<"stFRInfo[i].width:"<<stFRInfo[i].w<<endl;
				cout<<"stFRInfo[i].height:"<<stFRInfo[i].h<<endl; */
				
				
			}
			
			
				
			
/* 			u64PTS = stFrame.stVFrame.u64PTS;
			FDProcessSaveResult(&stFRInfo[0], contours.size(), u64PTS); */
			
			
			}
			if(testcount > 200)
			{
				objend = get_cur_time();
				printf("objend %dms\n", objend/1000);
				objtotal += (objend- objstart)/1000;
				printf("objtotal cost %dms\n", objtotal);
			
			}
				
				
			if(contours.size()== 0)
			{
				countsizetest++;
				
			}	
				
			if(countsizetest > 10)
			{
				testcount = 0;
				objtotal = 0;
				countsizetest = 0;
			}
			
			
			endTime = clock();
			
			
			//totalTime += (double)(endTime - startTime)/CLOCKS_PER_SEC;

			//cout<<"totalTime:"<<totalTime<<"s"<<endl;
			 
			if(objtotal >= 40)
			{
				
				testcount = 0;
				objtotal = 0;
				flag = 0;
				
				 for(i=0;i<160;i++)
				{
				for(j=0;j<160;j++)
					{
						col2[i][j]=img.at<uchar>(Point(i,j));//save latest value
						colq2[i][j].push(col2[i][j]);//push latest value
						if(count<npixel)
							{
								sum2[i][j]=sum2[i][j]+col2[i][j];
								avgq2[i][j]=0;	//avg zero till queue is full
							}
						if(count>=npixel)//Background acquisition complete
							{ 
								colq2[i][j].pop();//take latest pixel
								sum2[i][j]=sum2[i][j]+col2[i][j]-colq2[i][j].front();//take sum of latest 150 pixels
								avgq2[i][j]=sum2[i][j]/npixel;
						
							
							}
							back.at<uchar>(Point(i,j))=avgq2[i][j];//get averaged background
							if(col2[i][j]-avgq2[i][j]>10 || col2[i][j]-avgq2[i][j]<(-10))
							{
								diff.at<uchar>(Point(i,j))=col2[i][j];// BG modelling step
	
							}
					}
				} 
			}
			s32Ret = HI_MPI_VPSS_ReleaseChnFrame(VpssGrp, VpssChn, &stFrame);
		
		
			
	}
	
#endif
	
	return 0;
}
